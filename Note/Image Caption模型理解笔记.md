# Image Caption模型理解笔记

## 模型目标

检测出图像中的物体

理解物体之间的相互关系

用合理的语言表达出来

## 基础模型

NIC，Neural Image Caption

CNN+RNN

CNN使用InceptionV3，RNN使用LSTM

考虑将此模型中的CNN换成InceptionV4、Densenet、Resnet，以提高CNN对图片特征的学习能力

## 加入注意力机制模型

CNN的空间特性能够提取出图片不同位置的特征，让RNN（即Decoder）在解码时拥有在这些位置特征中选择的能力，就是注意力机制。

## 加入高层语义模型

CNN最后的分类层可以学习得到大量诸如"图中有没有人"、"图中有没有猫"类似的高层信息，这种高层于一与最终生成的语句非常相关。

简单来说，假设要从图中找到$c$类物体，那么使用$c$个Softmax层进行分类。

在训练时，从所有描述中提取出现最频繁的$c$个单词作为CNN的总标签，每个图片的训练标签直接从其描述语句中获取，即描述语句中出现了哪些标签；

训练完成后，可以针对每张图片提取高层的语义表达向量$V_{att}(I)$，代替$CNN(I)$作为RNN的输入。



